{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xEWpayxURuUn"
      },
      "source": [
        "# Crawl Data Twitter > 2000 Tweets\n",
        "The crawling process was done using Tweet-Harvest. Written by Helmi Satria on  March 30th 2024.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6S00x_f6-GeD"
      },
      "outputs": [],
      "source": [
        "#@title Twitter Auth Token\n",
        "\n",
        "twitter_auth_token = 'd26f3efd5ec907775cf77326f7e897f0c2fe448e' # change this auth token"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "4UIL1x21P9rQ",
        "outputId": "02c91727-4ece-4500-a899-709442d35c21"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (2.2.2)\n",
            "Requirement already satisfied: numpy>=1.23.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (2.0.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.1)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
            "Hit:1 https://cloud.r-project.org/bin/linux/ubuntu jammy-cran40/ InRelease\n",
            "Hit:2 http://archive.ubuntu.com/ubuntu jammy InRelease\n",
            "Hit:3 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  InRelease\n",
            "Hit:4 https://deb.nodesource.com/node_20.x nodistro InRelease\n",
            "Hit:5 http://archive.ubuntu.com/ubuntu jammy-updates InRelease\n",
            "Hit:6 http://security.ubuntu.com/ubuntu jammy-security InRelease\n",
            "Hit:7 http://archive.ubuntu.com/ubuntu jammy-backports InRelease\n",
            "Hit:8 https://r2u.stat.illinois.edu/ubuntu jammy InRelease\n",
            "Hit:9 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy InRelease\n",
            "Hit:10 https://ppa.launchpadcontent.net/graphics-drivers/ppa/ubuntu jammy InRelease\n",
            "Hit:11 https://ppa.launchpadcontent.net/ubuntugis/ppa/ubuntu jammy InRelease\n",
            "Reading package lists... Done\n",
            "W: Skipping acquire of configured file 'main/source/Sources' as repository 'https://r2u.stat.illinois.edu/ubuntu jammy InRelease' does not seem to provide it (sources.list entry misspelt?)\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "ca-certificates is already the newest version (20240203~22.04.1).\n",
            "curl is already the newest version (7.81.0-1ubuntu1.20).\n",
            "gnupg is already the newest version (2.2.27-3ubuntu2.1).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 41 not upgraded.\n",
            "gpg: cannot open '/dev/tty': No such device or address\n",
            "curl: (23) Failed writing body\n",
            "deb [signed-by=/etc/apt/keyrings/nodesource.gpg] https://deb.nodesource.com/node_20.x nodistro main\n",
            "Hit:1 https://cloud.r-project.org/bin/linux/ubuntu jammy-cran40/ InRelease\n",
            "Hit:2 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  InRelease\n",
            "Hit:3 https://deb.nodesource.com/node_20.x nodistro InRelease\n",
            "Hit:4 http://security.ubuntu.com/ubuntu jammy-security InRelease\n",
            "Hit:5 https://r2u.stat.illinois.edu/ubuntu jammy InRelease\n",
            "Hit:6 http://archive.ubuntu.com/ubuntu jammy InRelease\n",
            "Hit:7 http://archive.ubuntu.com/ubuntu jammy-updates InRelease\n",
            "Hit:8 http://archive.ubuntu.com/ubuntu jammy-backports InRelease\n",
            "Hit:9 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy InRelease\n",
            "Hit:10 https://ppa.launchpadcontent.net/graphics-drivers/ppa/ubuntu jammy InRelease\n",
            "Hit:11 https://ppa.launchpadcontent.net/ubuntugis/ppa/ubuntu jammy InRelease\n",
            "Reading package lists... Done\n",
            "W: Skipping acquire of configured file 'main/source/Sources' as repository 'https://r2u.stat.illinois.edu/ubuntu jammy InRelease' does not seem to provide it (sources.list entry misspelt?)\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "nodejs is already the newest version (20.19.0-1nodesource1).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 41 not upgraded.\n",
            "v20.19.0\n"
          ]
        }
      ],
      "source": [
        "# Import required Python package\n",
        "!pip install pandas\n",
        "\n",
        "# Install Node.js (because tweet-harvest built using Node.js)\n",
        "!sudo apt-get update\n",
        "!sudo apt-get install -y ca-certificates curl gnupg\n",
        "!sudo mkdir -p /etc/apt/keyrings\n",
        "!curl -fsSL https://deb.nodesource.com/gpgkey/nodesource-repo.gpg.key | sudo gpg --dearmor -o /etc/apt/keyrings/nodesource.gpg\n",
        "\n",
        "!NODE_MAJOR=20 && echo \"deb [signed-by=/etc/apt/keyrings/nodesource.gpg] https://deb.nodesource.com/node_$NODE_MAJOR.x nodistro main\" | sudo tee /etc/apt/sources.list.d/nodesource.list\n",
        "\n",
        "!sudo apt-get update\n",
        "!sudo apt-get install nodejs -y\n",
        "\n",
        "!node -v"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6-1EBrlediWE"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LYDR51dJlVlX",
        "outputId": "2793f20a-d9a8-4450-a412-14c8011503a6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1G\u001b[0K⠙\u001b[1G\u001b[0K⠹\u001b[1G\u001b[0K⠸\u001b[1G\u001b[0K⠼\u001b[1G\u001b[0K⠴\u001b[1G\u001b[0K\u001b[1m\u001b[32mTweet Harvest [v2.6.1]\u001b[39m\u001b[22m\n",
            "\u001b[1m\u001b[32m\u001b[39m\u001b[22m\n",
            "\u001b[34mResearch by \u001b[39m\u001b[1m\u001b[34mHelmi Satria\u001b[39m\u001b[22m\u001b[34m\u001b[39m\n",
            "\u001b[34mUse it for Educational Purposes only!\u001b[39m\n",
            "\u001b[34m\u001b[39m\n",
            "\u001b[33mThis script uses Chromium Browser to crawl data from Twitter with \u001b[1myour Twitter auth token\u001b[22m.\u001b[39m\n",
            "\u001b[33mPlease enter your Twitter auth token when prompted.\u001b[39m\n",
            "\u001b[33m\u001b[39m\n",
            "\u001b[31m\u001b[1mNote:\u001b[22m\u001b[39m Keep your access token secret! Don't share it with anyone else.\n",
            "\u001b[31m\u001b[1mNote:\u001b[22m\u001b[39m This script only runs on your local device.\n",
            "\n",
            "\u001b[34m\u001b[39m\n",
            "\u001b[34mOpening twitter search page...\u001b[39m\n",
            "\u001b[34m\u001b[39m\n",
            "\u001b[90m\u001b[39m\n",
            "\u001b[90m-- Scrolling... (1)\u001b[39m\u001b[90m (2)\u001b[39m\u001b[90m (3)\u001b[39m\u001b[90m (4)\u001b[39m\u001b[33m\u001b[39m\n",
            "\u001b[33mFilling in keywords: prabowo OR demo lang:id since:2025-03-19 until:2025-03-23\u001b[39m\n",
            "\u001b[33m\u001b[39m\n",
            "\u001b[90m (5)\u001b[39m\u001b[34m\u001b[39m\n",
            "\u001b[34m\u001b[39m\n",
            "\u001b[34mYour tweets saved to: /content/tweets-data/RUU_TNI_TWT_Danar_04.csv\u001b[39m\n",
            "\u001b[33mTotal tweets saved: 15\u001b[39m\n",
            "\u001b[34m\u001b[39m\n",
            "\u001b[34m\u001b[39m\n",
            "\u001b[34mYour tweets saved to: /content/tweets-data/RUU_TNI_TWT_Danar_04.csv\u001b[39m\n",
            "\u001b[33mTotal tweets saved: 31\u001b[39m\n",
            "\u001b[90m\u001b[39m\n",
            "\u001b[90m-- Scrolling... (1)\u001b[39m\u001b[34m\u001b[39m\n",
            "\u001b[34m\u001b[39m\n",
            "\u001b[34mYour tweets saved to: /content/tweets-data/RUU_TNI_TWT_Danar_04.csv\u001b[39m\n",
            "\u001b[33mTotal tweets saved: 51\u001b[39m\n",
            "\u001b[90m\u001b[39m\n",
            "\u001b[90m-- Scrolling... (1)\u001b[39m\u001b[34m\u001b[39m\n",
            "\u001b[34m\u001b[39m\n",
            "\u001b[34mYour tweets saved to: /content/tweets-data/RUU_TNI_TWT_Danar_04.csv\u001b[39m\n",
            "\u001b[33mTotal tweets saved: 67\u001b[39m\n",
            "\u001b[90m\u001b[39m\n",
            "\u001b[90m-- Scrolling... (1)\u001b[39m\u001b[90m (2)\u001b[39m\u001b[34m\u001b[39m\n",
            "\u001b[34m\u001b[39m\n",
            "\u001b[34mYour tweets saved to: /content/tweets-data/RUU_TNI_TWT_Danar_04.csv\u001b[39m\n",
            "\u001b[33mTotal tweets saved: 83\u001b[39m\n",
            "\u001b[90m\u001b[39m\n",
            "\u001b[90m-- Scrolling... (1)\u001b[39m\u001b[34m\u001b[39m\n",
            "\u001b[34m\u001b[39m\n",
            "\u001b[34mYour tweets saved to: /content/tweets-data/RUU_TNI_TWT_Danar_04.csv\u001b[39m\n",
            "\u001b[33mTotal tweets saved: 102\u001b[39m\n",
            "\u001b[90m\u001b[39m\n",
            "\u001b[90m--Taking a break, waiting for 10 seconds...\u001b[39m\n",
            "\u001b[90m\u001b[39m\n",
            "\u001b[90m-- Scrolling... (1)\u001b[39m\u001b[90m (2)\u001b[39m\u001b[34m\u001b[39m\n",
            "\u001b[34m\u001b[39m\n",
            "\u001b[34mYour tweets saved to: /content/tweets-data/RUU_TNI_TWT_Danar_04.csv\u001b[39m\n",
            "\u001b[33mTotal tweets saved: 116\u001b[39m\n",
            "\u001b[34m\u001b[39m\n",
            "\u001b[34m\u001b[39m\n",
            "\u001b[34mYour tweets saved to: /content/tweets-data/RUU_TNI_TWT_Danar_04.csv\u001b[39m\n",
            "\u001b[33mTotal tweets saved: 134\u001b[39m\n",
            "\u001b[90m\u001b[39m\n",
            "\u001b[90m-- Scrolling... (1)\u001b[39m\u001b[90m (2)\u001b[39m\u001b[90m (3)\u001b[39m\u001b[90m (4)\u001b[39m\u001b[90m (5)\u001b[39m\u001b[34m\u001b[39m\n",
            "\u001b[34m\u001b[39m\n",
            "\u001b[34mYour tweets saved to: /content/tweets-data/RUU_TNI_TWT_Danar_04.csv\u001b[39m\n",
            "\u001b[33mTotal tweets saved: 153\u001b[39m\n",
            "\u001b[90m\u001b[39m\n",
            "\u001b[90m-- Scrolling... (1)\u001b[39m\u001b[34m\u001b[39m\n",
            "\u001b[34m\u001b[39m\n",
            "\u001b[34mYour tweets saved to: /content/tweets-data/RUU_TNI_TWT_Danar_04.csv\u001b[39m\n",
            "\u001b[33mTotal tweets saved: 169\u001b[39m\n",
            "\u001b[34m\u001b[39m\n",
            "\u001b[34m\u001b[39m\n",
            "\u001b[34mYour tweets saved to: /content/tweets-data/RUU_TNI_TWT_Danar_04.csv\u001b[39m\n",
            "\u001b[33mTotal tweets saved: 187\u001b[39m\n",
            "\u001b[90m\u001b[39m\n",
            "\u001b[90m-- Scrolling... (1)\u001b[39m\u001b[90m (2)\u001b[39m\u001b[90m (3)\u001b[39m\u001b[90m (4)\u001b[39m\u001b[90m (5)\u001b[39m\u001b[34m\u001b[39m\n",
            "\u001b[34m\u001b[39m\n",
            "\u001b[34mYour tweets saved to: /content/tweets-data/RUU_TNI_TWT_Danar_04.csv\u001b[39m\n",
            "\u001b[33mTotal tweets saved: 204\u001b[39m\n",
            "\u001b[90m\u001b[39m\n",
            "\u001b[90m--Taking a break, waiting for 10 seconds...\u001b[39m\n",
            "\u001b[90m\u001b[39m\n",
            "\u001b[90m-- Scrolling... (1)\u001b[39m\u001b[90m (2)\u001b[39m\u001b[90m (3)\u001b[39m\u001b[90m (4)\u001b[39m\u001b[34m\u001b[39m\n",
            "\u001b[34m\u001b[39m\n",
            "\u001b[34mYour tweets saved to: /content/tweets-data/RUU_TNI_TWT_Danar_04.csv\u001b[39m\n",
            "\u001b[33mTotal tweets saved: 217\u001b[39m\n",
            "\u001b[90m\u001b[39m\n",
            "\u001b[90m-- Scrolling... (1)\u001b[39m\u001b[90m (2)\u001b[39m\u001b[34m\u001b[39m\n",
            "\u001b[34m\u001b[39m\n",
            "\u001b[34mYour tweets saved to: /content/tweets-data/RUU_TNI_TWT_Danar_04.csv\u001b[39m\n",
            "\u001b[33mTotal tweets saved: 231\u001b[39m\n",
            "\u001b[34m\u001b[39m\n",
            "\u001b[34m\u001b[39m\n",
            "\u001b[34mYour tweets saved to: /content/tweets-data/RUU_TNI_TWT_Danar_04.csv\u001b[39m\n",
            "\u001b[33mTotal tweets saved: 244\u001b[39m\n",
            "\u001b[34m\u001b[39m\n",
            "\u001b[34m\u001b[39m\n",
            "\u001b[34mYour tweets saved to: /content/tweets-data/RUU_TNI_TWT_Danar_04.csv\u001b[39m\n",
            "\u001b[33mTotal tweets saved: 260\u001b[39m\n",
            "\u001b[90m\u001b[39m\n",
            "\u001b[90m-- Scrolling... (1)\u001b[39m\u001b[34m\u001b[39m\n",
            "\u001b[34m\u001b[39m\n",
            "\u001b[34mYour tweets saved to: /content/tweets-data/RUU_TNI_TWT_Danar_04.csv\u001b[39m\n",
            "\u001b[33mTotal tweets saved: 277\u001b[39m\n",
            "\u001b[90m\u001b[39m\n",
            "\u001b[90m-- Scrolling... (1)\u001b[39m\u001b[90m (2)\u001b[39m\u001b[90m (3)\u001b[39m\u001b[34m\u001b[39m\n",
            "\u001b[34m\u001b[39m\n",
            "\u001b[34mYour tweets saved to: /content/tweets-data/RUU_TNI_TWT_Danar_04.csv\u001b[39m\n",
            "\u001b[33mTotal tweets saved: 296\u001b[39m\n",
            "\u001b[90m\u001b[39m\n",
            "\u001b[90m-- Scrolling... (1)\u001b[39m\u001b[34m\u001b[39m\n",
            "\u001b[34m\u001b[39m\n",
            "\u001b[34mYour tweets saved to: /content/tweets-data/RUU_TNI_TWT_Danar_04.csv\u001b[39m\n",
            "\u001b[33mTotal tweets saved: 311\u001b[39m\n",
            "\u001b[90m\u001b[39m\n",
            "\u001b[90m--Taking a break, waiting for 10 seconds...\u001b[39m\n",
            "\u001b[90m\u001b[39m\n",
            "\u001b[90m-- Scrolling... (1)\u001b[39m\u001b[34m\u001b[39m\n",
            "\u001b[34m\u001b[39m\n",
            "\u001b[34mYour tweets saved to: /content/tweets-data/RUU_TNI_TWT_Danar_04.csv\u001b[39m\n",
            "\u001b[33mTotal tweets saved: 329\u001b[39m\n",
            "\u001b[34m\u001b[39m\n",
            "\u001b[34m\u001b[39m\n",
            "\u001b[34mYour tweets saved to: /content/tweets-data/RUU_TNI_TWT_Danar_04.csv\u001b[39m\n",
            "\u001b[33mTotal tweets saved: 346\u001b[39m\n",
            "\u001b[90m\u001b[39m\n",
            "\u001b[90m-- Scrolling... (1)\u001b[39m\u001b[90m (2)\u001b[39m\u001b[90m (3)\u001b[39m\u001b[90m (4)\u001b[39m\u001b[90m (5)\u001b[39m\u001b[90m (6)\u001b[39m\u001b[90m (7)\u001b[39m\u001b[34m\u001b[39m\n",
            "\u001b[34m\u001b[39m\n",
            "\u001b[34mYour tweets saved to: /content/tweets-data/RUU_TNI_TWT_Danar_04.csv\u001b[39m\n",
            "\u001b[33mTotal tweets saved: 363\u001b[39m\n",
            "\u001b[90m\u001b[39m\n",
            "\u001b[90m-- Scrolling... (1)\u001b[39m\u001b[34m\u001b[39m\n",
            "\u001b[34m\u001b[39m\n",
            "\u001b[34mYour tweets saved to: /content/tweets-data/RUU_TNI_TWT_Danar_04.csv\u001b[39m\n",
            "\u001b[33mTotal tweets saved: 379\u001b[39m\n",
            "\u001b[90m\u001b[39m\n",
            "\u001b[90m-- Scrolling... (1)\u001b[39m\u001b[34m\u001b[39m\n",
            "\u001b[34m\u001b[39m\n",
            "\u001b[34mYour tweets saved to: /content/tweets-data/RUU_TNI_TWT_Danar_04.csv\u001b[39m\n",
            "\u001b[33mTotal tweets saved: 396\u001b[39m\n",
            "\u001b[90m\u001b[39m\n",
            "\u001b[90m-- Scrolling... (1)\u001b[39m\u001b[34m\u001b[39m\n",
            "\u001b[34m\u001b[39m\n",
            "\u001b[34mYour tweets saved to: /content/tweets-data/RUU_TNI_TWT_Danar_04.csv\u001b[39m\n",
            "\u001b[33mTotal tweets saved: 412\u001b[39m\n",
            "\u001b[90m\u001b[39m\n",
            "\u001b[90m--Taking a break, waiting for 10 seconds...\u001b[39m\n",
            "\u001b[90m\u001b[39m\n",
            "\u001b[90m-- Scrolling... (1)\u001b[39m\u001b[34m\u001b[39m\n",
            "\u001b[34m\u001b[39m\n",
            "\u001b[34mYour tweets saved to: /content/tweets-data/RUU_TNI_TWT_Danar_04.csv\u001b[39m\n",
            "\u001b[33mTotal tweets saved: 428\u001b[39m\n",
            "\u001b[90m\u001b[39m\n",
            "\u001b[90m-- Scrolling... (1)\u001b[39m\u001b[90m (2)\u001b[39m\u001b[90m (3)\u001b[39m\u001b[90m (4)\u001b[39m\u001b[34m\u001b[39m\n",
            "\u001b[34m\u001b[39m\n",
            "\u001b[34mYour tweets saved to: /content/tweets-data/RUU_TNI_TWT_Danar_04.csv\u001b[39m\n",
            "\u001b[33mTotal tweets saved: 447\u001b[39m\n",
            "\u001b[90m\u001b[39m\n",
            "\u001b[90m-- Scrolling... (1)\u001b[39m\u001b[34m\u001b[39m\n",
            "\u001b[34m\u001b[39m\n",
            "\u001b[34mYour tweets saved to: /content/tweets-data/RUU_TNI_TWT_Danar_04.csv\u001b[39m\n",
            "\u001b[33mTotal tweets saved: 466\u001b[39m\n",
            "\u001b[90m\u001b[39m\n",
            "\u001b[90m-- Scrolling... (1)\u001b[39m\u001b[90m (2)\u001b[39m\u001b[90m (3)\u001b[39m\u001b[90m (4)\u001b[39m\u001b[34m\u001b[39m\n",
            "\u001b[34m\u001b[39m\n",
            "\u001b[34mYour tweets saved to: /content/tweets-data/RUU_TNI_TWT_Danar_04.csv\u001b[39m\n",
            "\u001b[33mTotal tweets saved: 479\u001b[39m\n",
            "\u001b[90m\u001b[39m\n",
            "\u001b[90m-- Scrolling... (1)\u001b[39m\u001b[34m\u001b[39m\n",
            "\u001b[34m\u001b[39m\n",
            "\u001b[34mYour tweets saved to: /content/tweets-data/RUU_TNI_TWT_Danar_04.csv\u001b[39m\n",
            "\u001b[33mTotal tweets saved: 492\u001b[39m\n",
            "\u001b[90m[v2.6.1]\u001b[39m Error parsing response json: {\"_type\":\"Response\",\"_guid\":\"response@9da45cac7f5020c7a7979fef91dacd1e\"}\n",
            "\u001b[90m[v2.6.1]\u001b[39m Most likely, you have already exceeded the Twitter rate limit. Read more on https://x.com/elonmusk/status/1675187969420828672.\n",
            "\u001b[90m[v2.6.1]\u001b[39m Error parsing response json: {\"_type\":\"Response\",\"_guid\":\"response@98e999bcd99bf170dfde45c364e7635a\"}\n",
            "\u001b[90m[v2.6.1]\u001b[39m Most likely, you have already exceeded the Twitter rate limit. Read more on https://x.com/elonmusk/status/1675187969420828672.\n",
            "\u001b[90m[v2.6.1]\u001b[39m Error parsing response json: {\"_type\":\"Response\",\"_guid\":\"response@1e424c8b54b1594513f94135ed7de288\"}\n",
            "\u001b[90m[v2.6.1]\u001b[39m Most likely, you have already exceeded the Twitter rate limit. Read more on https://x.com/elonmusk/status/1675187969420828672.\n",
            "\u001b[90m[v2.6.1]\u001b[39m Error: page.waitForTimeout: Target page, context or browser has been closed\n",
            "\u001b[34mKeywords: prabowo OR demo lang:id since:2025-03-19 until:2025-03-23\u001b[39m\n",
            "\u001b[93mTwitter Harvest v 2.6.1\u001b[39m\n",
            "node:internal/process/promises:391\n",
            "    triggerUncaughtException(err, true /* fromPromise */);\n",
            "    ^\n",
            "\n",
            "page.screenshot: Target page, context or browser has been closed\n",
            "    at crawl (/root/.npm/_npx/d28e8c2154917da4/node_modules/\u001b[4mtweet-harvest\u001b[24m/dist/bin.js:470:16)\n",
            "\n",
            "Node.js v20.19.0\n",
            "^C\n"
          ]
        }
      ],
      "source": [
        "# Crawl Data\n",
        "\n",
        "filename = 'RUU TNI_TWT_Danar_04.csv'\n",
        "search_keyword = 'prabowo OR demo lang:id since:2025-03-19 until:2025-03-23'\n",
        "\n",
        "limit = 600\n",
        "\n",
        "!npx -y tweet-harvest@2.6.1 -o \"{filename}\" -s \"{search_keyword}\" --tab \"LATEST\" -l {limit} --token {twitter_auth_token}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 367
        },
        "id": "HvAG3hPvQDqk",
        "outputId": "042fa356-4cf1-44f6-9a5f-9cfa789b1328"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: '/content/tweets-data/RUU_TNI_Danar_01.csv'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-12-ed70889a0e0d>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m# Read the CSV file into a pandas DataFrame\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdelimiter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\",\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;31m# Display the DataFrame\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m   1024\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1025\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1026\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1027\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1028\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    618\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    619\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 620\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    621\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    622\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1618\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1619\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mIOHandles\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1620\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1621\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1622\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1878\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1879\u001b[0m                     \u001b[0mmode\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m\"b\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1880\u001b[0;31m             self.handles = get_handle(\n\u001b[0m\u001b[1;32m   1881\u001b[0m                 \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1882\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    871\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoding\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    872\u001b[0m             \u001b[0;31m# Encoding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 873\u001b[0;31m             handle = open(\n\u001b[0m\u001b[1;32m    874\u001b[0m                 \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    875\u001b[0m                 \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/tweets-data/RUU_TNI_Danar_01.csv'"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Specify the path to your CSV file\n",
        "file_path = '/content/tweets-data/RUU_TNI_Danar_04.csv'\n",
        "\n",
        "# Read the CSV file into a pandas DataFrame\n",
        "df = pd.read_csv(file_path, delimiter=\",\")\n",
        "\n",
        "# Display the DataFrame\n",
        "display(df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eRfDl54waHC4"
      },
      "outputs": [],
      "source": [
        "# Cek jumlah data yang didapatkan\n",
        "\n",
        "num_tweets = len(df)\n",
        "print(f\"Jumlah tweet dalam dataframe adalah {num_tweets}.\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}